{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lottery_Ticket_Hypothesis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0jbs8UM47/jr9QUkhMy1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amifunny/Deep-Learning-Notebook/blob/master/Lottery_Ticket_Hypothesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXJYH2IbanOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  This notebook closely follow this paper - 'https://arxiv.org/pdf/1803.03635.pdf'.\n",
        "  Its based on Principles of Pruning.\n",
        "  Unique Idea Behind this is that When we get sub network that is pruned,\n",
        "  it is said to have won the initialization lottery.\n",
        "  And hence can be retrained using the starting variable.\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsEiu3OAikiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "\n",
        "from tensorflow.python.framework import tensor_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mz6XjGzij-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "raw_data,info = tfds.load('cifar10',split=['train','test'],with_info=True)\n",
        "\n",
        "print(info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LUG18rFirtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AluqnCBCitYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data,test_data = raw_data[0],raw_data[1]\n",
        "\n",
        "def map_func(data):\n",
        "\n",
        "  img = tf.squeeze( ( tf.cast( data['image'] , tf.float32 )-127.5 )/127.5 )\n",
        "  label = tf.cast( data['label'] , tf.float32 )\n",
        "\n",
        "  return img,label\n",
        "\n",
        "train_data = train_data.map( map_func )\n",
        "\n",
        "train_data = train_data.shuffle(3000)\n",
        "train_batches = train_data.batch( batch_size , drop_remainder=True )\n",
        "\n",
        "test_data = test_data.map( map_func )\n",
        "\n",
        "test_data = test_data.shuffle(3000)\n",
        "test_batches = test_data.batch( batch_size , drop_remainder=True )\n",
        "\n",
        "for one_b in train_batches.take(1):\n",
        "  print( one_b[1][0] )\n",
        "  show = plt.imshow(one_b[0][0,:,:],cmap='gray')\n",
        "  plt.show()\n",
        "  print( one_b[0].shape )\n",
        "  print( one_b[1].shape )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EDfAAiec8vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A sinple Conv-6 model with ~5 million params\n",
        "inputs = tf.keras.layers.Input( (32,32,3) )\n",
        "\n",
        "out = layers.Conv2D( 128 , (3,3) , activation='relu' , padding='SAME' )(inputs)\n",
        "out = layers.Conv2D( 128 , (3,3) , activation='relu' , padding='SAME' )(out)\n",
        "out = layers.MaxPool2D()(out)\n",
        "out = layers.Conv2D( 256 , (3,3) , activation='relu' , padding='SAME' )(out)\n",
        "out = layers.Conv2D( 256 , (3,3) , activation='relu' , padding='SAME' )(out)\n",
        "out = layers.MaxPool2D()(out)\n",
        "out = layers.Conv2D( 512 , (3,3) , activation='relu' , padding='SAME' )(out)\n",
        "out = layers.MaxPool2D()(out)\n",
        "out = layers.Conv2D( 512 , (3,3) , activation='relu' , padding='SAME' )(out)\n",
        "out = layers.MaxPool2D()(out)\n",
        "\n",
        "out = layers.Flatten()(out)\n",
        "out = layers.Dense( 512 , activation = 'relu' )(out)\n",
        "out = layers.Dense( 256 , activation = 'relu' )(out)\n",
        "outputs = layers.Dense( 10 , activation = 'softmax' )(out)\n",
        "\n",
        "model = tf.keras.Model( inputs , outputs )\n",
        "model.summary()\n",
        "# Save the init weights for pruning\n",
        "model.save_weights( 'reset_init.h5' )\n",
        "model_reset_w = model.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcytIK4f7VtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the model\n",
        "def test_error( model , test_batches ):\n",
        "\n",
        "  acc = tf.keras.metrics.Accuracy()\n",
        "  acc.reset_states()\n",
        "\n",
        "  for batch in test_batches:\n",
        "\n",
        "    pred = model( batch[0] )\n",
        "    pred_argmax = tf.argmax( pred , -1 )\n",
        "\n",
        "    acc.update_state( batch[1] , pred_argmax )\n",
        "    y = batch[1]\n",
        "\n",
        "  test_error =  1.0-acc.result()\n",
        "  print(\"Error is ==> {}\".format( test_error ) )\n",
        "\n",
        "  return test_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jayHkn1qi4PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "mean = tf.keras.metrics.Mean()\n",
        "\n",
        "train_model = model\n",
        "\n",
        "def training(l_rate = 0.001,epochs=10,batch_size = 256):\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop( l_rate )\n",
        "\n",
        "  ctr = 0\n",
        "  with tf.device('/device:GPU:0'):\n",
        "\n",
        "    for e in range(epochs):\n",
        "      \n",
        "      print( 100*test_error( train_model , test_batches ) )\n",
        "\n",
        "      print(\"********* EPOCH :: {}\".format(e))\n",
        "\n",
        "      train_ex = train_data.shuffle(10000)\n",
        "      train_batches = train_ex.batch( batch_size , drop_remainder=True )\n",
        "      ctr = 0\n",
        "      mean.reset_states()\n",
        "\n",
        "      for batch in train_batches:\n",
        "      \n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "          pred = train_model( batch[0] , training=True )\n",
        "          \n",
        "          cost = loss_fn( batch[1] , pred )\n",
        "\n",
        "          if ctr%40==0:\n",
        "            print(\"Loss is === >  {}\".format(cost))\n",
        "\n",
        "          ctr = ctr+1\n",
        "\n",
        "        mean.update_state(cost)        \n",
        "        grads = tape.gradient( cost,train_model.trainable_variables )\n",
        "        optimizer.apply_gradients(zip(grads,train_model.trainable_variables))\n",
        "\n",
        "      print(\"EPOCh cost is ===>  {}\".format(mean.result()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go2Ot5xA7LYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initial Full Training\n",
        "training()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FdoehUzD43J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights( 'Trained_Weights.h5' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H7gTwKb7vTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( \"Percent is ==> {}\".format( 100*test_error( model , test_batches )) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "150VVqFCkQBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  \n",
        "  So now we have a trained Model with hefty ~5 million parameters.\n",
        "  Trained on CIFAR-10 dataset.\n",
        "  Now we will endevour our Pruning Journey.\n",
        "\n",
        "  Steps to follow according to PAPER :-\n",
        "\n",
        "  0. Declare and Store Model Initializations (done!)\n",
        "  1. GET a Trained Model. (done!)\n",
        "  2. Make weights zeros on basis of their ranking and Fine-Tune.\n",
        "  3. Reset remaining to initial Parameters.\n",
        "  4. Repeat steps 2 & 3 untill performance degrade.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHgJL8Nwj-PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pruning on basis on Weights Value\n",
        "\n",
        "def pruning( prev_degree , degree ):\n",
        "\n",
        "  current_degree = prev_degree + degree\n",
        "  new_weights = []\n",
        "\n",
        "  for i,variable in enumerate(model.weights):\n",
        "    \n",
        "    var_shape = variable.shape\n",
        "    current_flat = tf.reshape( variable , (1,-1) )\n",
        "    limiting_idx = tf.cast( current_flat.shape[-1]*current_degree , tf.int32 )\n",
        "    sorted_idx = tf.argsort( tf.math.abs(current_flat) ,axis=-1,direction='ASCENDING' )\n",
        "    index_to_zero = np.squeeze(sorted_idx.numpy()[0,:limiting_idx] )\n",
        "\n",
        "    reset_variable = model_reset_w[i].numpy()\n",
        "    reset_flat = np.reshape( reset_variable , (1,-1) )\n",
        "    reset_flat[ 0 , index_to_zero ] = 0.0\n",
        "\n",
        "    pruned_var = tf.convert_to_tensor( reset_flat )\n",
        "\n",
        "    rebuilt = tf.reshape( pruned_var , var_shape )\n",
        "    new_weights.append(rebuilt)\n",
        "\n",
        "  model.set_weights( new_weights )  \n",
        "\n",
        "  return current_degree"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PphmI3PREEgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets do the pruning\n",
        "degree = 0.1\n",
        "prev_degree = 0.0\n",
        "total_steps = 15\n",
        "\n",
        "model.load_weights( 'Trained_Weights.h5' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXCcf16-ra8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prev_degree = pruning(prev_degree,degree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpwsnAUS202T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prune_degree_list = []\n",
        "prune_acc_list = []\n",
        "\n",
        "# Ofcourse Pruning is Computationally expensive\n",
        "\n",
        "for prune_step in range(total_steps):\n",
        "  \n",
        "  # After upto 0.5 prune rate\n",
        "  if prune_step==4:\n",
        "    degree = 0.05\n",
        "\n",
        "  if prev_degree>0.90:\n",
        "    break\n",
        "\n",
        "  # Fine Tuning\n",
        "  training(0.0005,5)\n",
        "  # Pruning\n",
        "  prev_degree = pruning(prev_degree,degree)\n",
        "\n",
        "  print(\"*******************************************************************\")\n",
        "  print(\"-------------------- One Step Prune -------------------------------\")\n",
        "  prune_acc = 100*test_error( model , test_batches )\n",
        "  print( \"Percent is ==> {}\".format( prune_acc ) )\n",
        "  prune_degree_list.append( prev_degree )\n",
        "  prune_acc_list.append( prune_acc )\n",
        "  print(\"*******************************************************************\")\n",
        "\n",
        "\n",
        "  model.save_weights('pruneW_with_degree_{:.2f}.h5'.format(prev_degree))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66T3fgl-CwLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot( prune_degree_list , prune_acc_list )\n",
        "plt.xlabel('Prune Error')\n",
        "plt.ylabel('Prune Degree')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3V0IkpxSQXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We get a good sparse netwrok upto 70% less parameters\n",
        "# But equally good accuracy.\n",
        "# Now according to paper the subnetwork\n",
        "# We got after pruning the weights had win the initialization lottery!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M6z0LYxKbZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('pruneW_with_degree_0.70.h5')\n",
        "best_pruned_weights =  model.weights\n",
        "print( \"Percent is ==> {}\".format( 100*test_error( model , test_batches )) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZSm8Y54KLme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We ranodmize non-zero weights\n",
        "random_pruned_weights = []\n",
        "\n",
        "for variable in model.weights:\n",
        "    \n",
        "  random_w = tf.where( variable!=0 , x=tf.random.normal(variable.shape) , y=variable )\n",
        "  random_pruned_weights.append( random_w )\n",
        "\n",
        "model.set_weights( random_pruned_weights )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jsz1PRgMTy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# of course we will get no accuracy\n",
        "# bcz of random weights\n",
        "print( \"Percent is ==> {}\".format( 100*test_error( model , test_batches )) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxVkBL6iL9pE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and train the model\n",
        "training(0.00001,10)\n",
        "# Ofcourse this network can't be trained with random initialization.\n",
        "# Hence our Hypothesis is true,\n",
        "# The Final Pruned Network has nodes which has won Init Lottery!\n",
        "# And we get a network with 70% less parameters!"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}