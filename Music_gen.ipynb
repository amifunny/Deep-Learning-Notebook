{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_gen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORA+lCFHmIbtewXgvMUKIr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amifunny/Deep-Learning-Notebook/blob/master/Music_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA-f42E9n0oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWXTJDtqD2Df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from music21 import *\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVOozKPokKXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download data form her == >'https://drive.google.com/file/d/1qnQVK17DNVkU19MgVA4Vg88zRDvwCRXw/view?usp=sharing'\n",
        "# and upload 'schubert.zip' to this notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spxwC3FQEQQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip schubert.zip -d midi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9RKz0JhEUtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining function to read MIDI files\n",
        "def read_midi(file):\n",
        "    \n",
        "    print(\"Loading Music File:\",file)\n",
        "    \n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "  \n",
        "    #grouping based on different instruments\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "\n",
        "    #Looping over all the instruments\n",
        "    for part in s2.parts:\n",
        "    \n",
        "        #select elements of only piano\n",
        "        if 'Piano' in str(part): \n",
        "        \n",
        "            notes_to_parse = part.recurse() \n",
        "      \n",
        "            #finding whether a particular element is note or a chord\n",
        "            for element in notes_to_parse:\n",
        "                \n",
        "                #note\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                \n",
        "                #chord\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybTD86mbFlA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/midi/'\n",
        "all_midi_files = os.listdir( base_dir )\n",
        "song_list = []\n",
        "\n",
        "for each_file in all_midi_files:\n",
        "    \n",
        "    song_list.append( read_midi( base_dir + each_file ) )\n",
        "\n",
        "print( len(all_midi_files) )\n",
        "print( len(song_list) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWwAjOry-VvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( song_list[5].shape )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Uj5AaSLLxbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the vocab\n",
        "vocab_set = set()\n",
        "\n",
        "for each_song in song_list:\n",
        "    \n",
        "    vocab_set.update( each_song )\n",
        "\n",
        "vocab_list = list(vocab_set)\n",
        "print(vocab_list)\n",
        "print( len(vocab_list) )    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNLT9VOlNdTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a dictionery\n",
        "int_to_note = {}\n",
        "note_to_int = {}\n",
        "\n",
        "for i in range( len(vocab_list) ):\n",
        "\n",
        "    int_to_note[i] = vocab_list[i]\n",
        "    note_to_int[ vocab_list[i] ] = i\n",
        "\n",
        "print(int_to_note)\n",
        "print(note_to_int)\n",
        "print( len(note_to_int) )\n",
        "\n",
        "# #########################\n",
        "vocab_size = len(note_to_int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU53quE4PMYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert note seq to int seq\n",
        "int_x_seq=[]\n",
        "int_y_seq=[]\n",
        "\n",
        "# what we want model to learn is predict\n",
        "# next node after seeing some \"timestep nodes\"\n",
        "# ie after seeing 32 notes predict 33rd\n",
        "timesteps = 32\n",
        "\n",
        "for each_song in song_list:\n",
        "\n",
        "    num_of_chunks = each_song.shape[-1]-timesteps\n",
        "    for i in range(num_of_chunks):\n",
        "        \n",
        "        temp_x = [ note_to_int[w] for w in each_song[i:i+timesteps] ]\n",
        "        temp_y = note_to_int[ each_song[i+timesteps] ]\n",
        "        \n",
        "        int_x_seq.append( temp_x )\n",
        "        int_y_seq.append( temp_y )\n",
        "\n",
        "print(len(int_x_seq))\n",
        "print(len(int_y_seq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvJGPYhe_Qkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind = 6\n",
        "print( int_x_seq[ind] )\n",
        "print( int_y_seq[ind] )\n",
        "print( len(int_x_seq[ind]) )\n",
        "print( type(int_x_seq[ind]) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcrLmWjzWguZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = 0\n",
        "def get_model():\n",
        "\n",
        "    model =  tf.keras.Sequential([\n",
        "          tf.keras.layers.Embedding(vocab_size,16),\n",
        "          tf.keras.layers.LSTM(32,\n",
        "                        return_sequences=True),\n",
        "          tf.keras.layers.LSTM(32,\n",
        "                        return_sequences=True),\n",
        "          tf.keras.layers.LSTM(32),\n",
        "          tf.keras.layers.Dense(64,activation='relu'),\n",
        "          tf.keras.layers.Dense(vocab_size,activation='softmax') \n",
        "      ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FBlko-uZP6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15Alnu3MRkRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffle_x = []\n",
        "shuffle_y = []\n",
        "\n",
        "perm_index = np.random.permutation( len(int_x_seq) )\n",
        "\n",
        "for i in perm_index:\n",
        "  shuffle_x.append( int_x_seq[i] )\n",
        "  shuffle_y.append( int_y_seq[i] )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBOIQOuOZ9Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_val = 1000\n",
        "\n",
        "x_tf = tf.convert_to_tensor(shuffle_x[:-num_of_val])\n",
        "y_tf = tf.convert_to_tensor(shuffle_y[:-num_of_val])\n",
        "\n",
        "print(x_tf.shape)\n",
        "\n",
        "val_x = shuffle_x[-num_of_val:-1]\n",
        "print(len(val_x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJYGOIHXAZeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( x_tf[5] )\n",
        "print( y_tf[5] )\n",
        "\n",
        "print( x_tf[6] )\n",
        "print( y_tf[6] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykpxFegnZoax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = tf.keras.losses.SparseCategoricalCrossentropy( )\n",
        "optimizer = tf.keras.optimizers.Adam(0.0005)\n",
        "mean = tf.keras.metrics.Mean()\n",
        "\n",
        "batch_size = 32\n",
        "num_of_batches = int( x_tf.shape[0]/batch_size )\n",
        "epochs = 10\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  \n",
        "  for e in range(epochs):\n",
        "\n",
        "    ctr = 0\n",
        "    mean.reset_states()\n",
        "\n",
        "    for i in range( num_of_batches ):  \n",
        "\n",
        "      x_batch = x_tf[i*batch_size:(i+1)*batch_size]\n",
        "      y_batch = tf.expand_dims( y_tf[i*batch_size:(i+1)*batch_size] , -1 )\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        \n",
        "        pred = model( x_batch )\n",
        "        loss = loss_func( y_batch , pred )\n",
        "\n",
        "      mean.update_state(loss)\n",
        "\n",
        "      grad = tape.gradient(loss,model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grad,model.trainable_variables))\n",
        "\n",
        "      if ctr%500==0:\n",
        "          print(\"loss is  ===>  {}\".format(mean.result()))\n",
        "\n",
        "          print( tf.squeeze(y_batch) )\n",
        "          print( tf.squeeze( tf.argmax(pred,-1) ) )\n",
        "\n",
        "\n",
        "      ctr = ctr + 1\n",
        "\n",
        "    print(\"Epoch {} === > {}\".format(e,mean.result()))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2piQ9Av0nkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.trainable_variables"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGtyi2PkpO3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('music_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOLRgKaVdLYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_music(start_salt):\n",
        "\n",
        "    gen_steps = 200\n",
        "    \n",
        "    music_step = len(start_salt)\n",
        "    # print( music_step )\n",
        "\n",
        "    pred_list = start_salt\n",
        "\n",
        "    # print(pred_list)\n",
        "    temperature=0.1\n",
        "\n",
        "    for i in range( gen_steps ):\n",
        "\n",
        "      init_music = np.array(pred_list[:i+music_step] )\n",
        "      init_tf = tf.expand_dims( tf.convert_to_tensor( init_music ) , 0 )\n",
        "\n",
        "      # print(init_tf)\n",
        "      pred_one = model(init_tf)\n",
        "      pred_hot = tf.squeeze( tf.argmax(pred_one,-1) )\n",
        "\n",
        "      predictions = pred_one / temperature\n",
        "      pred_val = tf.random.categorical(predictions, num_samples=1)\n",
        "\n",
        "\n",
        "      pred_val = (tf.squeeze(pred_val)).numpy()\n",
        "      pred_list.append( pred_val  )\n",
        "\n",
        "    return pred_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSRMxNjOgynW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_init = val_x[-5][:-1]\n",
        "my_music = gen_music(temp_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hepoNJ-vi01Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "note_music = []\n",
        "for each_ele in my_music:\n",
        "\n",
        "    note_music.append(int_to_note[each_ele])\n",
        "\n",
        "print(note_music)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Fd7OzPjOS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is midi related function that i took from internet it simply turn vocab into music\n",
        "def convert_to_midi(prediction_output):\n",
        "   \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        \n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                \n",
        "                cn=int(current_note)\n",
        "                new_note = note.Note(cn)\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "                \n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "            \n",
        "        # pattern is a note\n",
        "        else:\n",
        "            \n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 1\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='music.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KhCIYArjdgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert_to_midi(note_music)\n",
        "# download the music.mid file from files explorer on left in colab and listen to your own sweet creation"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}