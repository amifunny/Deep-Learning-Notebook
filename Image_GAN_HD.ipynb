{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_GAN_HD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfHmPXRSFuLWUxleb8dBKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amifunny/Deep-Learning-Notebook/blob/master/Image_GAN_HD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OmExH3ehYbd",
        "colab_type": "code",
        "outputId": "7c3033d4-424f-442b-8ee9-f57aef00ec99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# kaggle requirements\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "\"\"\"\n",
        "  ** This Notebook uses Kaggle Dataset. \n",
        "  If not a user , Sign in here - 'https://www.kaggle.com/'\n",
        "  If already a user , Obtain your api_token by - 'https://www.kaggle.com/docs/api#authentication\n",
        "\"\"\" \n",
        "api_token = {\"username\":\"<your_user_name>\",\"key\":\"<key_here>\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\",'w') as file:\n",
        "    json.dump( api_token , file )\n",
        "    file.close()\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avv5-YyMg5fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import kaggle\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqImnDA5hZ1D",
        "colab_type": "code",
        "outputId": "4d00b641-c5df-4891-a851-25eaf927e99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# dataset at 'https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "# !kaggle competitions download -c dogs-vs-cats\n",
        "\n",
        "!kaggle datasets download -d abhikjha/utk-face-cropped"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading utk-face-cropped.zip to /content\n",
            " 97% 225M/232M [00:04<00:00, 48.5MB/s]\n",
            "100% 232M/232M [00:04<00:00, 50.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOA3N_rBhjRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# **!unzip train.zip -d data\n",
        "\n",
        "!unzip utk-face-cropped.zip -d face_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piXJIZBMhncs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes arg \"test1\" or \"train\", and noi(number of images)\n",
        "# def get_data( data_type, start=0,end=1000):\n",
        "\n",
        "#     master_dir = '/content/data/'+ data_type +'/'\n",
        "\n",
        "#     all_images = os.listdir(master_dir)[start:end]\n",
        "\n",
        "#     data_x = []\n",
        "\n",
        "#     for img_file in all_images:\n",
        "\n",
        "#         img = Image.open(master_dir+img_file)\n",
        "#         img_arr = ( np.array( img.resize((96,96)) )/255.0 )\n",
        "#         data_x.append( img_arr )\n",
        "\n",
        "#     return data_x\n",
        "\n",
        "def get_data( data_type, start=0,end=1000):\n",
        "\n",
        "    master_dir = '/content/face_data/'+ data_type +'/'\n",
        "\n",
        "    all_images = os.listdir(master_dir)[start:end]\n",
        "\n",
        "    data_x = []\n",
        "\n",
        "    for img_file in all_images:\n",
        "\n",
        "        try:\n",
        "          img = Image.open(master_dir+img_file)\n",
        "          img_arr = ( np.array( img.resize((96,96)) )/255.0 )\n",
        "          data_x.append( img_arr )\n",
        "        except:\n",
        "          continue\n",
        "\n",
        "    return data_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaC44Ll6hs-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# domain_imgs = get_data( \"train\",0,-1 )\n",
        "domain_imgs = get_data( 'utkcropped' , 0,10000 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG8sfrRgYucJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(domain_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDDlYyBxhy_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the data\n",
        "show = plt.imshow( domain_imgs[1] )\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WIMNENaqNt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_batch(dom_imgs,batch_size):\n",
        "\n",
        "    num_of_batches = int(len(dom_imgs)/batch_size)\n",
        "    \n",
        "    img_shape = dom_imgs[0].shape\n",
        "    dom_batches = []\n",
        "    \n",
        "    for i in range(num_of_batches):\n",
        "        \n",
        "        dom_batch = tf.convert_to_tensor( dom_imgs[i*batch_size:(i+1)*batch_size] )\n",
        "        dom_batches.append( dom_batch )\n",
        "\n",
        "    return dom_batches,num_of_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gChfBguSkCDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  DISCRIMINATOR MODEL\n",
        "\"\"\"\n",
        "\n",
        "inputs = tf.keras.layers.Input((96,96,3))\n",
        "\n",
        "out = tf.keras.layers.Conv2D( 32,(5,5),strides=(2,2) , padding='same' )(inputs)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "out = tf.keras.layers.Dropout(0.2)(out)\n",
        "\n",
        "\n",
        "out = tf.keras.layers.Conv2D( 64,(5,5),strides=(2,2), padding='same' )(out)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "out = tf.keras.layers.Dropout(0.2)(out)\n",
        "\n",
        "\n",
        "out = tf.keras.layers.Conv2D( 128,(5,5),strides=(2,2), padding='same' )(out)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "out = tf.keras.layers.Dropout(0.2)(out)\n",
        "\n",
        "out = tf.keras.layers.Conv2D( 256,(5,5),strides=(2,2), padding='same' )(out)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "out = tf.keras.layers.Dropout(0.2)(out)\n",
        "\n",
        "out = tf.keras.layers.Flatten()(out)\n",
        "outputs = tf.keras.layers.Dense( 1 )(out)\n",
        "\n",
        "D_model=0\n",
        "D_model = tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "D_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDVLBf9GlStw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  GENERATOR MODEL\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "inputs = tf.keras.layers.Input((100,))\n",
        "\n",
        "out = tf.keras.layers.Dense(3*3*1024)(inputs)\n",
        "out = tf.keras.layers.BatchNormalization()(out)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "\n",
        "out = tf.keras.layers.Reshape(target_shape=(3,3,1024))(out)\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(256,(5,5),strides=(2,2),padding=\"same\",use_bias=False)(out)\n",
        "out = tf.keras.layers.BatchNormalization()(out)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(128,(5,5),strides=(2,2),padding=\"same\",use_bias=False)(out)\n",
        "out = tf.keras.layers.BatchNormalization()(out)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding=\"same\",use_bias=False)(out)\n",
        "out = tf.keras.layers.BatchNormalization()(out)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(32,(5,5),strides=(2,2),padding=\"same\",use_bias=False)(out)\n",
        "out = tf.keras.layers.BatchNormalization()(out)\n",
        "out = tf.keras.layers.LeakyReLU()(out)\n",
        "\n",
        "outputs = tf.keras.layers.Conv2DTranspose(3,(5,5),strides=(1,1),use_bias=False,activation='tanh',padding=\"same\")(out)\n",
        "\n",
        "G_model = 0\n",
        "G_model=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "G_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "642GiKVVJgCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try_gen = G_model( tf.random.normal([1,100]) , training=False )\n",
        "print(try_gen.shape)\n",
        "# print( try_gen )\n",
        "# print( tf.cast( try_gen[0,:,:,:]*127.5+127.5 , tf.uint8 ) )\n",
        "show = plt.imshow( tf.cast( try_gen[0,:,:,:]*127.5+127.5 , tf.uint8 ) )\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWJA0nakXJEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = tf.random.normal([ 16 , 100 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGBnbwI-HDSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow( tf.cast( predictions[i, :, :, :] * 127.5 + 127.5 , tf.uint8 )  , cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5p4JH_h2QZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#********************\n",
        "batch_size = 128\n",
        "l_rate = 0.0001\n",
        "ctr=0\n",
        "epochs=50\n",
        "# k -factor\n",
        "k=1\n",
        "subset_size = 1024\n",
        "#********************\n",
        "\n",
        "d_optimizer = tf.keras.optimizers.Adam( l_rate )\n",
        "g_optimizer = tf.keras.optimizers.Adam( l_rate )\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  for e in range(epochs):\n",
        "    \n",
        "    print(\"********* EPOCH :: {}\".format(e))\n",
        "\n",
        "    # display.clear_output(wait=True)\n",
        "    generate_and_save_images(G_model,\n",
        "                             e + 1,\n",
        "                             seed)\n",
        "\n",
        "    g_cost = 0\n",
        "    start = 0\n",
        "    end = start + subset_size\n",
        "\n",
        "    while True:\n",
        "\n",
        "      subset = domain_imgs[start:end]\n",
        "      if end>10000:\n",
        "        break\n",
        "      start = end\n",
        "      end = start + subset_size\n",
        "      batches,_ = prep_batch(subset,batch_size)\n",
        "\n",
        "      for batch_true in batches:\n",
        "     \n",
        "        batch_noise = tf.random.normal( (batch_size,100 ) )\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "\n",
        "          pred_true = tf.squeeze( D_model( batch_true , training=True ) )\n",
        "          batch_false = G_model(batch_noise, training=True)\n",
        "          pred_false = tf.squeeze( D_model(batch_false, training=True) )\n",
        "\n",
        "          d_cost = discriminator_loss(pred_true,pred_false)\n",
        "          g_cost = generator_loss(pred_false)\n",
        "\n",
        "        if ctr%10==0:\n",
        "\n",
        "          print(\"optimally 1 for D : {}\".format(pred_true[:10]))\n",
        "          print(\"optimally 0 for D : {}\".format(pred_false[:10]))\n",
        "          print(\"D_Loss is === >  {}\".format(d_cost))\n",
        "          print(\"G_Loss is === >  {}\".format(g_cost))\n",
        "\n",
        "          generate_and_save_images(G_model,\n",
        "                             e + 1,\n",
        "                             seed)\n",
        "\n",
        "        ctr = ctr+1\n",
        "        \n",
        "        if ctr%k==0:\n",
        "          d_grads = tape.gradient( d_cost,D_model.trainable_variables )\n",
        "          d_optimizer.apply_gradients(zip(d_grads,D_model.trainable_variables))\n",
        "\n",
        "        g_grads = tape.gradient( g_cost,G_model.trainable_variables )\n",
        "        g_optimizer.apply_gradients(zip(g_grads,G_model.trainable_variables))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8gyCtpHeayq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Train it for 100 Epochs & see the results\n",
        "  Somewhat Good Right! If you are not getting good results , Restart the Notebook and Make Sure you don't Change anything.\n",
        "  GAN's are sensitive and give results only when every aspect is right eg. Activations,Dropout,Loss\n",
        "  See -- 'https://github.com/soumith/ganhacks'\n",
        "\n",
        "  Feel Free to Try Another Dataset : )\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}